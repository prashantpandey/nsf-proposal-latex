\section{Sketches}



The challenge of computing properties of massive data streams in limited space has inspired a deep and beautiful literature on streaming algorithms and database systems. In the dynamic streaming model, the input is defined by a sequence of items of length $N$ and only $O(\polylog N)$ {RAM} is available for computation. For most interesting graph problems, such as matchings or spanning forests, this is not enough space to even represent a solution. Algorithms for these problems instead use the dynamic semi-streaming model~\cite{insertonlysemistreaming}, which allows more space (specifically, $O(n \; \polylog n)$ \acro{RAM} is available for a graph of $n$ nodes and $m$ edges). Note that this is still not enough space to store the graph explicitly, unless the graph is sparse: any lossless representation requires $\Omega(m))$ space, which can be $\Omega(n^2)$ for the densest graphs. In this model, the input graph is defined by a stream of edge insertions and deletions, and this stream is delivered to the algorithm a small number of times (typically once).

Semi-streaming algorithms have several advantages that, in theory, make them powerful tools for computing on graphs at scale.  Since these algorithms require an up to $\Theta(n)$-factor less space than an explicit representation of a dense graph, they are able to process much larger graphs given a fixed amount of memory. Effectively, all dynamic semi-streaming algorithms are equivalent to linear sketching algorithms~\cite{li2014sketchuniversal}, which are highly parallelizable, easy to distribute, robust to arbitrarily ordered input streams, and have good data locality. In a nutshell, they trade more computation for a smaller space requirement. %\jdo{Is the previous sentence correct?}
The benefits of practical implementations of semi-streaming algorithms would be significant, vastly increasing the scale of graphs which can be processed even when these graphs are too large for fast memory, change over time, or even are generated in real time (for example, from sensors measuring large-scale real-world phenomena, or from dynamic connections or interactions in a large network).

While many dynamic semi-streaming graph algorithms\cite{Ahn2012, AhnGM12b, AhnGM13, GuhaMT15, KapralovLMMS13, ChitnisCEHMMV16, AssadiKL16, McGregorVV16, pagh2012colorful, 10.1007/978-3-662-48054-0_39, clustering, 10.1007/978-3-319-21398-9_57, streamsetbounds, Chakrabarti2015IncidenceGA, kveton2016graphical, CrouchMS13} are known in the theory literature, prior to our Sept.\ 2021 prototype~\cite{graphzeppelin}, there were \emph{no} implementations of these algorithms in use in academia or industry.  One of the primary bottlenecks of these algorithms is the high computational cost of their linear sketching subroutines. This difficulty leads us to the GPU.

\prashant{Add comp bio work in minhash for Jaccard similarity, edit distance, HyperlogLog.}


\begin{rproblem}
Can we develop algorithms that can replace hashing with batch sorting.
\end{rproblem}

% \prashant{Notes for Martin.}

% \prashant{Given a fastq file containing raw sequencing reads. Can we quickly and space-efficiently (maybe sublinear time and space?) estimate a frequency distribution for \kmers for a given $k$?
% Specifically, we are interested in estimating the total number of \kmers, the total number of distinct \kmers, the total number of \kmers with a given count C?}

\begin{rproblem}
Develop data structures for indexing and searching low-dimensional embeddings (based on minhash) for raw genomic and metagenomic data.
\end{rproblem}


\begin{rproblem}
Build a GPU-enabled cardinality estimator for \kmers in raw sequencing samples (genomic, transcriptomic, metageomic).
\end{rproblem}

% best distinct elements count sketch AFAIK: https://people.eecs.berkeley.edu/~minilek/publications/papers/f0.pdf this has likely been implemented, but i haven't verified. I will check if i have time. and for fun, a differentially private solution to the problem (which i have not read): https://arxiv.org/abs/2001.11932


\begin{rproblem}
Develop algorithms that are close to communication lower bound to compute the similarity score for two set of \kmers in a distributed setting.
\end{rproblem}



\begin{rproblem}
Design and build a system to compute similarity score (Jaccard index) for \kmer sets in a distributed-setting.
\end{rproblem}


% i am not super familiar with the work on sketching set similarity but this paper seems promising: https://www.itu.dk/people/pagh/papers/oddsketch.pdf there is also this implementation-focused paper that includes another sketch to solve the problem and mentions the prior paper: https://dl.acm.org/doi/abs/10.1145/3292500.3330825
