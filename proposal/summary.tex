%!TEX root =  proposal.tex

%% Don't actually need this - will submit txt.  Just want to estimate actual space
\begin{center}
\bf
\Large
Collaborative Research: PPoSS\@: Large: A Compact, Dynamic, and Distributed Data
Structure Library for Computational Biology

\medskip
\small
Michael A. Bender (SBU), Martin Farach-Colton (Rutgers), John Owens (UC Davis), Rob Patro (UMD), Prashant Pandey (Utah)
\end{center}

\noindent \textbf{\large Overview:}\\
Genomic sequencing data is being generated faster than ever due to modern sequencing technologies.
% , which is already producing petabyte-scale datasets.
Many applications in computational biology (\kmer analysis, single-cell transcriptomics, variant detection, transcript identification, raw sequence search, taxonomic classification, genome and metagenome assembly, and pangenomics) require processing raw sequencing data at the petabyte scales.
%
These computational-biology applications (and numerous others) use a set of common data structures to perform many data-analysis tasks, and their performance is bottlenecked by the data-structure and algorithm performance.

This project aims to build high-performance and scalable data analysis-pipelines for computational-biology applications. Specifically, we aim to develop new massively parallel and distributed data structures and algorithms for core computational biology data processing tasks. These new data structures and algorithms will have wide applicability in computational biology applications and beyond.
%
We will develop new \textbf{algorithmic theory} to design scalable data structures; we will develop new \textbf{systems} that implement our solutions in a scale-up manner,  both on CPUs as a prototype and GPUs for massive parallelism; we will develop a new framework to distribute our solutions in an \textbf{HPC} environment, so they scale out to clusters of GPUs; and finally we will validate out solutions on \textbf{computational biology} workloads.
%
Specifically, the data structures we propose to study are: \textbf{filters}, \textbf{sketches}, \textbf{hash tables}, \textbf{string indexes}, and related auxiliary data structures.  We will validate our solutions on \textbf{large-scale raw sequence search}, \textbf{single-cell preprocessing}, \textbf{taxonomic classification for metagenomic data}, \textbf{pangenomic indexing and analysis}, \textbf{metagenome assembly}, and others.

\noindent \textbf{\large Keywords:} Data structures, algorithms, computational biology, GPUs, high-performance computing (HPC).

\noindent \textbf{\large Intellectual Merit:}\\
If successful we will be able to perform complex data analyses to answer biological questions on terabyte- and petabyte-scale datasets. For example, raw sequencing data from sequence read archive (SRA) is already at petabyte scale, metagenomic data from Western Arctic and Rhizo are in terabytes, and population-scale pangenomic data from the 100,000 Genome Project contains the genomes of $\approx85$K individuals. Existing data structures and software tools fail to scale to these data sizes, making these publicly available and highly valuable data resources largely inert.

The projectâ€™s novelties are: a vertical-stack approach spanning theory and algorithms: highly concurrent, dynamic, and distributed data structures, systems: scale up using GPU acceleration, high-performance computing: scale out using distributed data structures, and applications: computational biology applications; new parallel and distributed data structures and algorithms to exploit the massive compute on GPUs applicable to other application domains; and an API for developers to quickly and seamlessly integrate high-performance and scalable data structures in applications.
%
Our team includes a highly interdisciplinary team of researchers across four focus areas: applications (computational biology), theory and algorithms, systems, and high-performance computing. The team is taking a holistic theory/systems/HPC/applications co-design approach to explore four tightly interconnected research modules. These research modules are structured from bottom-up across the computing stack.

\noindent \textbf{\large Broader Impacts: }\\
The primary broader impact of this work is to enhance the capability of bioinformatics applications to perform computations at the largest scales. Both accelerated computation (allowing quicker feedback and more experiments) and larger computation potentially accelerate the process of scientific discovery. Second, we expect that a high-quality library of distributed, scalable GPU data structures will find widespread utility in other application domains.
%
Beyond technical broader impacts, we propose outreach impacts through tutorial on using our data structure library in computational biology conferences and proposing week-long research seminars like Dagstuhl that we hope will bridge the gaps between computational biologists, CS theorists, and CS systems researchers.
