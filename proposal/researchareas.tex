\section{Research areas}

% The Project Description must contain a section titled "Research Areas" that must:

% Explicitly state and motivate at least four research areas covered (along with senior personnel with commensurate expertise);
% Describe the targeted distributed applications and systems, and the heterogeneous platforms on which they run; and
% Define relevant notions of scale and describe how scalability will be theoretically and experimentally evaluated for the targeted distributed applications and systems and heterogeneous platforms in (2) with respect to the full hardware/software stack.



\paragraph{Coverage areas.} 
Data structures are ubiquitous throughout the hardware/software stack, as a way to build scalable computational biology applications that can process petabyte-scale genomic data.
Data structures have become a bottleneck, but redesigning data structures for GPUs to exploit massive parallelism and scaling to distributed memory is tantamount to renegotiating the division of labor among system components---requiring a closely knit team and an approach that weighs the costs and benefits holistically.
Our team has extensive expertise in the following four research areas:

% \begin{itemize}[noitemsep,nolistsep]
\begin{description}
  \item[Theory and Algorithms (PIs Bender and Farach-Colton)]
    Bender and Farach-Colton have written numerous
    top-tier theory
    publications~\cite{DBLP:conf/stoc/BenderFK19,DBLP:conf/focs/BenderFGJM018,DBLP:conf/soda/BenderCCFJT19,DBLP:conf/soda/AfshaniBFFGT17,DBLP:conf/pods/BenderFJMMPX17,DBLP:conf/stoc/BenderKPY16,DBLP:conf/soda/BenderFGKM17,DBLP:conf/pods/BenderBJKMPSSZ16}
    and have made significant contributions the use of theoretically grounded algorithms in computer systems~\cite{BenderFaGo18,BenderFaJo12,BenderFaJo11,PandeyBeJo17,PandeyAlBe18,PandeyBeJo18,PandeyBeJo17c,DBLP:conf/icalp/ConwayFS18,betrfsmany,other}.
\john{It would be better to have a set of citations here closer to the topic of the proposal, e.g., data structures and/or scalability.}


    \item[GPU Systems (PIs Owens and Pandey)] Owens's research program in GPU computing~\cite{Owens:2007:ASO,Owens:2008:GC} spans nearly 20 years and includes representative research advances in fundamental algorithms~\cite{Sengupta:2007:SPF}, data structures~\cite{Lefohn:2006:GGE,Alcantara:2009:RPH}, % scalability to multiple GPUs~\cite{Stuart:2009:MPO,Stuart:2011:EMT,Stuart:2011:MMO,Pan:2017:MGA,Pan:2018:SBS,Chen:2022:SIP},
    performance engineering~\cite{Zhang:2011:AQP}, programming models~\cite{Gupta:2012:ASO, Tzeng:2010:TMF}, and applications~\cite{Wang:2017:GGG}.

    \item[High-Performance Computing (PIs Bender, Farach-Colton, Owens, and
        Pandey)] Bender, Farach-Colton, Owens, and Pandey have
      written a number of top-tier papers in HPC~\cite{pandey2020timely,bender2017two,eckstein2015pebbl,agrawal1989four,bender2008communication,greenberg1999enabling},
      and had considerable impact on HPC practice. \john{Again, specificity here is more helpful than just ``top-tier papers''. Please be more specific about the intersection between the cited work and the issues at hand here.}  PI Bender's and Phillips \john{Who is ``Phillips'' and what does Phillips have to do with this proposal?}
      work in HPC has focused on scheduling and  won a joint R\&D 100 Award for
      processor scheduling and allocation algorithms, which were licensed by
      Cray and incorporated into SLURM\@.  PIs Bender and Farach-Colton's company
      Tokutek deployed software to manage metadata in a large cloud storage
      service. Owens led the first implementation of MPI on GPUs~\cite{Stuart:2009:MPO:withouturl,Stuart:2011:EMT}, the first multi-GPU MapReduce~\cite{Stuart:2011:MMO}, and more recent work on scalable graph analytics on HPC machines~\cite{Pan:2018:SBS,Pan:2017:MGA,Chen:2022:SIP}.

    \item[Large-scale genomics (PIs Bender, Farach-Colton, and Pandey)]

\end{description}


\paragraph{Notions of Scale.}

Our proposed work address several notions of scale. First, multi-core parallelism on CPUs is critical to efficiently scale data structure to exploit CPU compute. Without a principled redesign of data structures, additional RAM and cores will be of diminishing value. 
Second, our work involves scaling up data structures by designing them for GPUs. GPUs are cost effective and offer massive parallelism. GPU data structures can achieve orders of magnitude speeds ups compared to CPUs. GPU data structures can help speed up computational-biology applications by orders of magnitude and process quickly analyse large-scale datasets.
Third, this includes scaling out data structures in distributed memory across multi-node GPUs to quickly process petabyte-scale genomic and metagenomic datasets. This will involve building distributed data structures that can offer low communication volume and low load imbalance. Prior work has demonstrated that data movement and load imbalance is the major bottleneck for achieving high performance in a distributed application.
Further, computational biology datasets available today are in terabyte and petabyte scale. For example, raw sequencing data from SRA~\cite{kodama2012sequence}, metagenomic data from WA and Rhizo~\cite{hofmeyr2020terabase}, and pangenomic data from 100K genome project~\cite{XXX}. To quickly process and perform biological analysis on these data we need to exploit the massive computing in modern GPUs (V100 and A100) and also the distributed computing infrastructure of super computers (Perlmutter and Summit).
